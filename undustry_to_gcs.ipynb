{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42794438-cf82-4237-a9ca-e7e9d70e643e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in /opt/conda/lib/python3.10/site-packages (30.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /opt/conda/lib/python3.10/site-packages (from faker) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from faker) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "048b06de-e065-4890-a0b8-718eb937de3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2024-10-18 08:28:42.700483\n",
      "Successfully uploaded file to GCS: yk53_av8o_.parquet\n",
      "Successfully uploaded file to GCS: i1qp_3mdc_.parquet\n",
      "Successfully uploaded file to GCS: 8j9f_c4hd_.parquet\n",
      "End time: 2024-10-18 08:28:43.941967\n",
      "Elapsed time: 0:00:01.241484\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import random\n",
    "import string\n",
    "from faker import Faker\n",
    "from datetime import datetime\n",
    "import io\n",
    "import nest_asyncio\n",
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Helper function to generate random IDs\n",
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.SystemRandom().choice(string.ascii_lowercase + string.digits) for _ in range(size))\n",
    "\n",
    "# Generate project IDs\n",
    "projects = [f\"{id_generator(4)}\" for _ in range(4)]\n",
    "\n",
    "# Generate tenant IDs\n",
    "Faker.seed(100)\n",
    "fake = Faker()\n",
    "tenants = [id_generator(4) for _ in range(10)]\n",
    "\n",
    "events = [\"unfreeze\", \"depressurize\", \"warm\", \"\", \"pressurize\", \"normalize\"]\n",
    "\n",
    "# GCP configuration\n",
    "gcp_bucket_name = \"myfirstproject-inputbucket\"\n",
    "gcp_credentials_path = \"double-balm-438113-f5-53067ace2784.json\"\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Define schema (same as before)\n",
    "humidity_schema = pa.struct([\n",
    "    ('temperature', pa.float64()),\n",
    "    ('relativeHumidity', pa.float64()),\n",
    "    ('updateTime', pa.timestamp('ms'))\n",
    "])\n",
    "\n",
    "event_data_schema = pa.struct([\n",
    "    ('humidity', humidity_schema)\n",
    "])\n",
    "\n",
    "event_schema = pa.struct([\n",
    "    ('eventId', pa.string()),\n",
    "    ('targetName', pa.string()),\n",
    "    ('eventType', pa.string()),\n",
    "    ('data', event_data_schema),\n",
    "    ('timestamp', pa.timestamp('ms'))\n",
    "])\n",
    "\n",
    "metadata_schema = pa.struct([\n",
    "    ('deviceId', pa.string()),\n",
    "    ('projectId', pa.string()),\n",
    "    ('deviceType', pa.string()),\n",
    "    ('productNumber', pa.string())\n",
    "])\n",
    "\n",
    "data_schema = pa.struct([\n",
    "    ('event', event_schema),\n",
    "    ('metadata', metadata_schema)\n",
    "])\n",
    "\n",
    "schema = pa.schema([\n",
    "    ('day', pa.int64()),\n",
    "    ('month', pa.int64()),\n",
    "    ('year', pa.int64()),\n",
    "    ('tenantId', pa.string()),\n",
    "    ('eventType', pa.string()),\n",
    "    ('eventId', pa.string()),\n",
    "    ('data', data_schema)\n",
    "])\n",
    "\n",
    "def upload_to_gcs(bucket, blob_name, data):\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.upload_from_string(data)\n",
    "    print(f'Successfully uploaded file to GCS: {blob_name}')\n",
    "\n",
    "async def generate_and_upload_data(i, bucket, executor):\n",
    "    # Generate sample data (same as before)\n",
    "    day = fake.day_of_month()\n",
    "    month = fake.month()\n",
    "    year = fake.year()\n",
    "    tenantId = random.choice(tenants)\n",
    "    project = random.choice(projects)\n",
    "    eventType = random.choice(events)\n",
    "    eventId = f\"{tenantId}_{id_generator(4)}\"\n",
    "    update_time = fake.date_time_this_year()\n",
    "    \n",
    "    sample_json_data = [{\n",
    "        \"day\": day,\n",
    "        \"month\": month,\n",
    "        \"year\": year,\n",
    "        \"tenantId\": tenantId,\n",
    "        \"eventType\": eventType,\n",
    "        \"eventId\": eventId,\n",
    "        \"data\": {\n",
    "            \"event\": {\n",
    "                \"eventId\": eventId,\n",
    "                \"targetName\": f\"projects/{project}/devices/{eventId}adg\",\n",
    "                \"eventType\": eventType,\n",
    "                \"data\": {\n",
    "                    \"humidity\": {\n",
    "                        \"temperature\": round(random.uniform(10.0, 40.0), 2),\n",
    "                        \"relativeHumidity\": round(random.uniform(30.0, 70.0), 2),\n",
    "                        \"updateTime\": update_time\n",
    "                    }\n",
    "                },\n",
    "                \"timestamp\": update_time\n",
    "            },\n",
    "            \"metadata\": {\n",
    "                \"deviceId\": f\"{eventId}adg\",\n",
    "                \"projectId\": project,\n",
    "                \"deviceType\": eventType,\n",
    "                \"productNumber\": \"102081\"\n",
    "            }\n",
    "        }\n",
    "    }]\n",
    "    \n",
    "    df = pd.DataFrame(sample_json_data)\n",
    "    df['day'] = df['day'].astype('int64')\n",
    "    df['month'] = df['month'].astype('int64')\n",
    "    df['year'] = df['year'].astype('int64')\n",
    "\n",
    "    table = pa.Table.from_pandas(df, schema=schema)\n",
    "    \n",
    "    try:\n",
    "        with io.BytesIO() as f:\n",
    "            pq.write_table(table, f, coerce_timestamps='ms')\n",
    "            f.seek(0)\n",
    "            blob_name = f\"{eventId}_.parquet\"\n",
    "            # Use ThreadPoolExecutor to run the upload in a separate thread\n",
    "            await asyncio.get_event_loop().run_in_executor(\n",
    "                executor, upload_to_gcs, bucket, blob_name, f.getvalue())\n",
    "    except Exception as e:\n",
    "        print(f'Error on iteration {i}: {e}')\n",
    "\n",
    "async def main():\n",
    "    n_rows = 3  # Number of rows\n",
    "    \n",
    "    # Set up GCP credentials and client\n",
    "    credentials = service_account.Credentials.from_service_account_file(gcp_credentials_path)\n",
    "    storage_client = storage.Client(credentials=credentials)\n",
    "    bucket = storage_client.bucket(gcp_bucket_name)\n",
    "    \n",
    "    # Create a ThreadPoolExecutor for running GCS uploads\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        tasks = [asyncio.ensure_future(generate_and_upload_data(i, bucket, executor)) for i in range(n_rows)]\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "# Run the main coroutine\n",
    "if __name__ == \"__main__\":\n",
    "    before = datetime.now()\n",
    "    print(\"Start time:\", before)\n",
    "\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(main())\n",
    "\n",
    "    after = datetime.now()\n",
    "    print(\"End time:\", after)\n",
    "    print(\"Elapsed time:\", after - before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9aee77-27a2-4cb0-92eb-3b542755f138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu113.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu113:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
